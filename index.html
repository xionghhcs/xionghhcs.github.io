<!DOCTYPE html>
<html>
  <head><meta name="generator" content="Hexo 3.9.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <meta name="description" content="真正的英雄是看清了生活的真相却依旧热爱生活的人---罗曼罗兰">
  <meta name="keyword" content="自然语言处理, 搜索">
  
    <link rel="shortcut icon" href="/css/images/logo.png">
  
  <title>
    
      拉格朗月
    
  </title>
  <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.css" rel="stylesheet">
  <link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/tomorrow.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/geopattern/1.2.3/js/geopattern.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/nprogress/0.2.0/nprogress.min.js"></script>
  
  
  
  
    <!-- MathJax support START -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support END -->
  


  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116276311-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-116276311-1');
    </script>

</head>
<div class="wechat-share">
  <img src="/css/images/logo.png">
</div>

  <body>
    <header class="header fixed-header">
  <div class="header-container">
    <a class="home-link" href="/">
      <div class="logo"></div>
      <span>拉格朗月</span>
    </a>
    <ul class="right-list">
      
        <li class="list-item">
          
            <a href="/" class="item-link active">Home</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/tags/" class="item-link">Tags</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/archives/" class="item-link">Archives</a>
          
        </li>
      
        <li class="list-item">
          
            <a href="/about/" class="item-link">About</a>
          
        </li>
      
    </ul>
    <div class="menu">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </div>
    <div class="menu-mask">
      <ul class="menu-list">
        
          <li class="menu-item">
            
              <a href="/" class="menu-link mobile-active">Home</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/tags/" class="menu-link">Tags</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/archives/" class="menu-link">Archives</a>
            
          </li>
        
          <li class="menu-item">
            
              <a href="/about/" class="menu-link">About</a>
            
          </li>
        
      </ul>
    </div>
  </div>
</header>

    <main class="app-body">
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/ff5c158e/">古文</a>
      </h2>
      <p class="article-date">2021年12月7日</p>
      
        
  <a href="/tags#古文" >
    <span class="tag-code">古文</span>
  </a>

      
      <div class="article-summary">
        
          
人一能之己百之，人十能之己千之。果能此道矣。虽愚必明，虽柔必强。


        
      </div>
      <a class="more" href="/posts/ff5c158e/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/ba23bdb7/">古文</a>
      </h2>
      <p class="article-date">2021年12月5日</p>
      
        
  <a href="/tags#古文" >
    <span class="tag-code">古文</span>
  </a>

      
      <div class="article-summary">
        
          
人生本是痴，不悟不成佛，不疯不成魔


        
      </div>
      <a class="more" href="/posts/ba23bdb7/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/c1c2e273/">tfidf和bm25</a>
      </h2>
      <p class="article-date">2021年12月5日</p>
      
        
  <a href="/tags#BM25" >
    <span class="tag-code">BM25</span>
  </a>

  <a href="/tags#TF-IDF" >
    <span class="tag-code">TF-IDF</span>
  </a>

      
      <div class="article-summary">
        
          
在最近的工作中，再次接触了bm25用来计算query和doc相关性的问题，在此记录一下bm25计算方法，备查阅。

相关性的度量搜索引擎最重要的职能，是根据用户输入的query，将文档库中最相关的内容返回给用户，因此相关性贯穿了搜索引擎的各个阶段。为此，我们需要对相关性进行定义和量化，基于 ...
        
      </div>
      <a class="more" href="/posts/c1c2e273/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/96d104d2/">SimCLS一个应用了对比学习的生成式摘要框架</a>
      </h2>
      <p class="article-date">2021年7月25日</p>
      
        
  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

  <a href="/tags#对比学习" >
    <span class="tag-code">对比学习</span>
  </a>

  <a href="/tags#生成式摘要" >
    <span class="tag-code">生成式摘要</span>
  </a>

      
      <div class="article-summary">
        
          

Paper Info论文：《SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization》
url: https://arxiv.org/pdf/2106.01890.pdf

        
      </div>
      <a class="more" href="/posts/96d104d2/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/3521d4f2/">基于相对位置编码的自注意力机制</a>
      </h2>
      <p class="article-date">2021年7月17日</p>
      
        
  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

  <a href="/tags#自注意力机制" >
    <span class="tag-code">自注意力机制</span>
  </a>

  <a href="/tags#相对位置编码" >
    <span class="tag-code">相对位置编码</span>
  </a>

      
      <div class="article-summary">
        
          
在Transformer模型中没有显示地在模型结构上建模输入序列地绝对或者相对位置信息，而是通过位置编码地方式，将每个位置用一个向量来表示，然后与元素对应地词向量相加来使得模型可以感知元素地位置信息。在论文《Self-Attention with Relative Position Rep ...
        
      </div>
      <a class="more" href="/posts/3521d4f2/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/28682/">入坑vim（一）</a>
      </h2>
      <p class="article-date">2021年6月27日</p>
      
        
  <a href="/tags#VIM" >
    <span class="tag-code">VIM</span>
  </a>

      
      <div class="article-summary">
        
          
工欲善其事，必先利其器









        
      </div>
      <a class="more" href="/posts/28682/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/4861/">Luna(Linear Unified Nested Attention)</a>
      </h2>
      <p class="article-date">2021年6月15日</p>
      
        
  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

  <a href="/tags#Attention" >
    <span class="tag-code">Attention</span>
  </a>

  <a href="/tags#Transformer" >
    <span class="tag-code">Transformer</span>
  </a>

  <a href="/tags#线性Attention" >
    <span class="tag-code">线性Attention</span>
  </a>

      
      <div class="article-summary">
        
          
Transformer的时间和空间复杂度都是和输入句子长度的平方，这种平方的时间、空间复杂度使得Transformer难以建模很长的序列。因此Transformer发布之后，很多研究者研究如何降低Attention中的复杂度，在不影响效果的前提下，使得Attention在时间和空间复杂度上 ...
        
      </div>
      <a class="more" href="/posts/4861/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/16269/">Synthesizer：transformer中的自注意力机制是否真的有必要？</a>
      </h2>
      <p class="article-date">2021年5月26日</p>
      
        
  <a href="/tags#NLP" >
    <span class="tag-code">NLP</span>
  </a>

  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

  <a href="/tags#Transformer" >
    <span class="tag-code">Transformer</span>
  </a>

  <a href="/tags#自注意力机制" >
    <span class="tag-code">自注意力机制</span>
  </a>

      
      <div class="article-summary">
        
          
Synthesizer模型是谷歌针对Transformer中的self-attention的进一步思考。毋庸置疑，Transformer模型无论是在NLP领域还是在CV领域都取得了巨大的成功，它抛弃了CNN、RNN这类常用的特征抽取模块，采用了self-attention机制来进行特征抽取 ...
        
      </div>
      <a class="more" href="/posts/16269/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/49d8fbdd/">Reformer</a>
      </h2>
      <p class="article-date">2021年4月17日</p>
      
        
  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

      
      <div class="article-summary">
        
          
        
      </div>
      <a class="more" href="/posts/49d8fbdd/">Read more</a>
    </article>
  
    <article class="article-card">
      <h2 class="article-head">
        <a href="/posts/34714856/">Transformer-XL让模型支持长序列建模</a>
      </h2>
      <p class="article-date">2021年4月10日</p>
      
        
  <a href="/tags#paper" >
    <span class="tag-code">paper</span>
  </a>

  <a href="/tags#TransformerXL" >
    <span class="tag-code">TransformerXL</span>
  </a>

  <a href="/tags#语言模型" >
    <span class="tag-code">语言模型</span>
  </a>

      
      <div class="article-summary">
        
          
Transformer-XL是Transformer模型的变种，主要用于解决长序列的建模问题。Transformer-XL可以看作是Transformer+RNN的结合体，不同的是Transformer-XL的递归是基于一个文本片段进行的。此外，Transformer-XL还引入了相对位置 ...
        
      </div>
      <a class="more" href="/posts/34714856/">Read more</a>
    </article>
  

  
    <div class="guide-pager">
  
    <a class="unvisible" href="/"><span class="page-arrow">←</span> Prev</a>
  
  
    <a href="/page/2/">Next<span class="page-arrow"> →</span></a>
  
</div>
  
</main>


    <div class="scroll-top">
  <span class="arrow-icon"></span>
</div>
    <footer class="app-footer">
  <p class="copyright">
    &copy; 2021 | Proudly powered by <a href="https://hexo.io" target="_blank">Hexo</a>
    <br>
    Theme by <a href="https://github.com/yanm1ng">yanm1ng</a>
  </p>
</footer>

<script>
  function async(u, c) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }
</script>
<script>
  async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
    FastClick.attach(document.body);
  })
</script>

<script>
  var hasLine = 'true';
  async("//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js", function(){
    $('figure pre').each(function(i, block) {
      var figure = $(this).parents('figure');
      if (hasLine === 'false') {
        figure.find('.gutter').hide();
      }
      var lang = figure.attr('class').split(' ')[1] || 'code';
      var codeHtml = $(this).html();
      var codeTag = document.createElement('code');
      codeTag.className = lang;
      codeTag.innerHTML = codeHtml;
      $(this).attr('class', '').empty().html(codeTag);
      figure.attr('data-lang', lang.toUpperCase());
      hljs.highlightBlock(block);
    });
  })
</script>
<!-- Baidu Tongji -->

<script src="/js/script.js"></script>
  </body>
</html>